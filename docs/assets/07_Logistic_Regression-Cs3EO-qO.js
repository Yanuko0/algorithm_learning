import{j as e}from"./index-BbTyzIcS.js";/* empty css                           */import{a as l}from"./ai_img-DywI196L.js";import{I as s}from"./index-0Y8keVtA.js";const x=()=>e.jsxs("div",{className:"full_page",children:[e.jsx("div",{className:"title",children:"回歸"}),e.jsxs("div",{className:"introduce",children:[e.jsxs("div",{className:"diagrambox",children:[e.jsx("p",{children:"邏輯回歸"}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.邏輯回歸,alt:"邏輯回歸"})})})}),e.jsxs("p",{children:["大家千萬不要被邏輯回歸的名字所迷惑,其實logistic regression並不是回歸任務的算法, 而是屬於分類任務算法。 根據歷史數據訓練模型, 未來預測樣本屬於哪一個類別的任務就是分類任務。",e.jsxs("ul",{children:[e.jsx("li",{children:"垃圾郵件分類"}),e.jsx("li",{children:"情感分析"}),e.jsx("li",{children:"圖像識別"}),e.jsx("li",{children:"信用卡欺詐檢測"}),e.jsx("li",{children:"疾病診斷"}),e.jsx("li",{children:"金融欺詐檢測"})]})]})]}),e.jsxs("div",{children:[e.jsx("p",{children:"邏輯回歸是分類算法, 為何名字中有回歸兩字"}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.邏輯回歸_01,alt:"邏輯回歸_01"})})})}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.邏輯回歸_02,alt:"邏輯回歸_02"})})})}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.邏輯回歸_03,alt:"邏輯回歸_03"})})})}),e.jsx("p",{children:"這麼做可以得到一個S型曲線(Sigmoid函數), 將線性回歸的值壓縮到0到1之間, 這樣就具備了概率含意;而概率值大於0.5我們認為樣本是正例, 反之我們認為樣本是負例, 這樣邏輯回歸創建之初就是做二分類任務用的。"})]})]}),e.jsxs("div",{className:"introduce",children:[e.jsxs("div",{className:"diagrambox",children:[e.jsx("p",{children:"如何求解算法模型"}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.如何求解算法模型,alt:"如何求解算法模型"})})})}),e.jsx("p",{children:"不同的算法模型(公式參數) 有不同的損失, 我們需要計算機不斷調整參數最後找出最優解參數(最佳模型)"})]}),e.jsxs("div",{children:[e.jsx("p",{children:"邏輯回歸可以做多分類嗎"}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.邏輯回歸_04,alt:"邏輯回歸_04"})})})}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.邏輯回歸_05,alt:"邏輯回歸_05"})})})})]}),e.jsxs("div",{children:[e.jsx("p",{children:"Softmax回歸"}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.Softmax回歸_01,alt:"Softmax回歸_01"})})})}),e.jsxs("p",{children:["Softmax回歸聽名字, 依然好像是做回歸任務的算法, 但其實它是做多分類任務的算法",e.jsxs("ul",{children:[e.jsx("li",{children:"籃球比賽勝負是二分類, 足球比賽勝平負就是多分類"}),e.jsx("li",{children:"識別手寫數字0和1是二分類, 識別手寫數字0-9就是多分類"})]}),"Softmax回歸算法是一種用於多分類問題的機器學習算法。 它可以幫助我們預測一個樣本屬於哪一類, 比如預測一張照片中的動物是狗、貓還是鳥"]})]}),e.jsxs("div",{children:[e.jsx("p",{children:"Softmax回歸算法表達式"}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.Softmax回歸_02,alt:"Softmax回歸_02"})})})}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.Softmax回歸_03,alt:"Softmax回歸_03"})})})}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.Softmax回歸_04,alt:"Softmax回歸_04"})})})})]}),e.jsxs("div",{children:[e.jsx("p",{children:"如何求解算法模型"}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.如何求解算法模型_01,alt:"如何求解算法模型_01"})})})}),e.jsx("p",{children:"不同的算法模型(公式參數), 有不同的損失值, 我們需要計算機不斷調整參數最後找出最優解參數(最佳模型)"})]}),e.jsxs("div",{children:[e.jsx("p",{children:"MultiLabel與MultiClass"}),e.jsx("p",{className:"diagram",children:e.jsx("div",{className:"commentaryBox",children:e.jsx(s.PreviewGroup,{preview:{onChange:(r,i)=>console.log(`current index: ${r}, prev index: ${i}`)},children:e.jsx(s,{src:l.MultiLabel與MultiClass,alt:"MultiLabel與MultiClass"})})})}),e.jsx("p",{children:e.jsxs("ul",{children:[e.jsx("li",{children:"Softmax回歸適合多分類模型, 因為互斥就是各類別概率之和必為1"}),e.jsx("li",{children:"邏輯回歸多分類轉多個二分類適合, 因為各個二分類模型是相互獨立的"})]})})]})]})]});export{x as default};
